{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with pre-trained embeddings\n",
    "\n",
    "* Make an RNN based model, but use word embeddings from word2vec or document tensor from Spacy (see hint below) as input (i.e. do not start with an embedding layer!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy document tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feeding a Spacy document tensor into an RNN can yield very nice results. Spacy is part of the conda environment, and should already be installed. Make sure that you download at least the medium size english model (taken from the quickstart from the Spacy docs)\n",
    "\n",
    "~~~sh\n",
    "python -m spacy download en_core_web_md\n",
    "~~~\n",
    "\n",
    "Example code for converting to tensors:\n",
    "~~~py\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "tensorized = doc.tensor\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T07:38:00.639681Z",
     "start_time": "2020-04-09T07:37:46.570846Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Masking, Input, LSTM, Flatten, Embedding, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T08:22:16.760079Z",
     "start_time": "2020-04-09T08:22:15.379940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/IMDB Dataset.csv')\n",
    "\n",
    "MAX_SEQ_LENGTH = 200\n",
    "SAMPLES = 10000\n",
    "\n",
    "def preprocess_imdb_raw_data(x):\n",
    "    x = re.sub(\"<br\\\\s*/?>\", \" \", x)\n",
    "    return x \n",
    "\n",
    "def reduce_sentence_length(x, max_seq_length=MAX_SEQ_LENGTH):\n",
    "    return ' '.join(x.split(' ')[:max_seq_length])\n",
    "\n",
    "X = [reduce_sentence_length(preprocess_imdb_raw_data(x)) for x in df['review'].values]\n",
    "\n",
    "y = df['sentiment'].apply(lambda x: int(x == 'positive')).values\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T08:22:21.879028Z",
     "start_time": "2020-04-09T08:22:21.432909Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T08:26:56.660454Z",
     "start_time": "2020-04-09T08:22:23.421872Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tensors = [nlp(x).tensor for x in X[:SAMPLES]]\n",
    "\n",
    "X_padded = pad_sequences(X_tensors, maxlen=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T08:27:04.938765Z",
     "start_time": "2020-04-09T08:27:04.441596Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y[:SAMPLES], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T08:27:12.948431Z",
     "start_time": "2020-04-09T08:27:12.495085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 200, 96)]         0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 200, 96)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               115200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 131,841\n",
      "Trainable params: 131,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Masking, Input, LSTM, Flatten, Embedding, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "doc_vec_size = 96\n",
    "\n",
    "def make_model(input_size=doc_vec_size, \n",
    "               dense_layer_size=128, \n",
    "               dropout_probs=0.2):\n",
    "\n",
    "    inp = Input(shape=[MAX_SEQ_LENGTH, input_size])\n",
    "    \n",
    "    x = Masking(mask_value=0)(inp)\n",
    "        \n",
    "    x = LSTM(dense_layer_size)(x)\n",
    "    x = Dense(dense_layer_size, activation=\"relu\")(x)\n",
    "    \n",
    "    x = Dropout(dropout_probs)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(\"adam\", loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = make_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T08:29:44.194458Z",
     "start_time": "2020-04-09T08:29:44.190058Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, filedir='../models'):\n",
    "    \n",
    "    with open(f\"{filedir}/rnn_model_pretrained.json\", \"w\") as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "\n",
    "    model.save_weights(f\"{filedir}/rnn_model_pretrained.h5\")\n",
    "    \n",
    "def load_model(filedir='../models'):\n",
    "\n",
    "    json_file = open(f\"{filedir}/rnn_model_pretrained.json\", 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    \n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(f\"{filedir}/rnn_model_pretrained.h5\")\n",
    "    \n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T08:32:07.159161Z",
     "start_time": "2020-04-09T08:29:51.870699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 27s 3ms/sample - loss: 0.6872 - accuracy: 0.5383\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 28s 4ms/sample - loss: 0.6418 - accuracy: 0.6310\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 28s 4ms/sample - loss: 0.5726 - accuracy: 0.7089\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 26s 3ms/sample - loss: 0.4781 - accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 26s 3ms/sample - loss: 0.3504 - accuracy: 0.8491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dbe42898>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T08:32:15.036557Z",
     "start_time": "2020-04-09T08:32:15.022164Z"
    }
   },
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T07:55:47.962305Z",
     "start_time": "2020-04-09T07:55:46.192582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.26      0.37       114\n",
      "           1       0.44      0.77      0.56        86\n",
      "\n",
      "    accuracy                           0.48       200\n",
      "   macro avg       0.52      0.52      0.46       200\n",
      "weighted avg       0.53      0.48      0.45       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_test_probs = model.predict(x=X_test)\n",
    "y_test_pred = (y_test_probs >= 0.5).astype(int)\n",
    "\n",
    "print(f\"Test: {classification_report(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T07:55:53.111498Z",
     "start_time": "2020-04-09T07:55:50.479551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74       385\n",
      "           1       0.73      0.92      0.82       415\n",
      "\n",
      "    accuracy                           0.78       800\n",
      "   macro avg       0.81      0.78      0.78       800\n",
      "weighted avg       0.80      0.78      0.78       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_probs = model.predict(x=X_train)\n",
    "y_train_pred = (y_train_probs >= 0.5).astype(int)\n",
    "\n",
    "print(f\"Train: {classification_report(y_train, y_train_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
