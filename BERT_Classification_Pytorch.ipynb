{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Classification Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3dec3bc44bf744c989abcf76b0adaf07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c39d298373f340d287575b8d4d0cd3bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_260fa87e975d4f868968b60510f1a667",
              "IPY_MODEL_c3a1cd6cffab494eaa7b9662e43f6392"
            ]
          }
        },
        "c39d298373f340d287575b8d4d0cd3bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "260fa87e975d4f868968b60510f1a667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01d9457651264b5dae2568edf9366d5f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d65534278894a56bb4edc7ce14ca3c9"
          }
        },
        "c3a1cd6cffab494eaa7b9662e43f6392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6fa4177eec0466784cea1c6d5c9380d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 813kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ab06dc7ff39452fbb85255147b59440"
          }
        },
        "01d9457651264b5dae2568edf9366d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d65534278894a56bb4edc7ce14ca3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6fa4177eec0466784cea1c6d5c9380d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ab06dc7ff39452fbb85255147b59440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b88687353f4849fb8416f8f5ce312ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8e8492862fd451093195601ac1ccfbf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d8d43783e074dd28da6dbaee8421585",
              "IPY_MODEL_5893c7dbce8743b8b1d155120c5015ee"
            ]
          }
        },
        "a8e8492862fd451093195601ac1ccfbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d8d43783e074dd28da6dbaee8421585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a4a783abe874a3987d3537d0303a640",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42e39ada1cc244a69f6cfa83bc4f05f1"
          }
        },
        "5893c7dbce8743b8b1d155120c5015ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63fa6c96176f463da858e0bc685d0f3e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 361/361 [00:11&lt;00:00, 31.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91679ab3502942e5b91fe9aff10c8d03"
          }
        },
        "0a4a783abe874a3987d3537d0303a640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42e39ada1cc244a69f6cfa83bc4f05f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63fa6c96176f463da858e0bc685d0f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91679ab3502942e5b91fe9aff10c8d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dcca7586f1641eb830335e1acaa6336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_730ad497fbcd4f27a07514283e4ae29e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a70084abd73040bdb989431d2543ae5d",
              "IPY_MODEL_a9bb268b635d4ebb95be00729b0c7e76"
            ]
          }
        },
        "730ad497fbcd4f27a07514283e4ae29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a70084abd73040bdb989431d2543ae5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ac0d181ba694221a5eb94145c140ac1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b17b2dd2b3b4381a216f7964e0fc0e4"
          }
        },
        "a9bb268b635d4ebb95be00729b0c7e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0eb011ad90c1427ea649500112dd0972",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 42.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d11f1362f34b4dfd91e4d559b3a14367"
          }
        },
        "6ac0d181ba694221a5eb94145c140ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b17b2dd2b3b4381a216f7964e0fc0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0eb011ad90c1427ea649500112dd0972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d11f1362f34b4dfd91e4d559b3a14367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvanommeren/nlp-benchmark/blob/master/BERT_Classification_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej",
        "colab_type": "text"
      },
      "source": [
        "# BERT Fine-Tuning Tutorial with PyTorch\n",
        "\n",
        "By Chris McCormick and Nick Ryan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPgpITmdwvX0",
        "colab_type": "text"
      },
      "source": [
        "*Revised on 3/20/20 - Switched to `tokenizer.encode_plus` and added validation loss. See [Revision History](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=IKzLS9ohzGVu) at the end for details.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab_type": "code",
        "outputId": "f517dae1-d410-4ab4-ba06-19239366614c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab_type": "code",
        "outputId": "35c49a15-c215-4c4d-ae3c-ecd0cbb6262c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab_type": "code",
        "outputId": "b6ff46d4-baf7-4c3a-aebe-503c8c1d0ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 29.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 4.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 15.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 26.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=5e7b303823d4591113f62912773241a0cce9ef151d9eac9625074f6da02a7c4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihMAlloSeNma",
        "colab_type": "code",
        "outputId": "17cd1410-66d0-4a56-ec15-6b1bfb90c429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGdCHoYbes00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file = 'gdrive/My Drive/Colab Notebooks/IMDB Dataset.csv'\n",
        "\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "SAMPLE_SIZE = 50000\n",
        "\n",
        "def preprocess_imdb_raw_data(x):\n",
        "    x = re.sub(\"<br\\\\s*/?>\", \" \", x)\n",
        "    return x \n",
        "\n",
        "X = [preprocess_imdb_raw_data(x) for x in df['review'].values][:SAMPLE_SIZE]\n",
        "\n",
        "y = df['sentiment'].apply(lambda x: int(x == 'positive')).values[:SAMPLE_SIZE]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = X\n",
        "labels = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct",
        "colab_type": "text"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab_type": "code",
        "outputId": "2832bb9c-b3a3-4d87-f97b-5628757456df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "3dec3bc44bf744c989abcf76b0adaf07",
            "c39d298373f340d287575b8d4d0cd3bc",
            "260fa87e975d4f868968b60510f1a667",
            "c3a1cd6cffab494eaa7b9662e43f6392",
            "01d9457651264b5dae2568edf9366d5f",
            "5d65534278894a56bb4edc7ce14ca3c9",
            "a6fa4177eec0466784cea1c6d5c9380d",
            "7ab06dc7ff39452fbb85255147b59440"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dec3bc44bf744c989abcf76b0adaf07",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIWAoWL2RK1p",
        "colab_type": "text"
      },
      "source": [
        "Now we're ready to perform the real tokenization.\n",
        "\n",
        "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
        "\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "4. Pad or truncate all sentences to the same length.\n",
        "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
        "\n",
        "The first four features are in `tokenizer.encode`, but I'm using `tokenizer.encode_plus` to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0SIJSHbdM-",
        "colab_type": "code",
        "outputId": "ed565af9-6f17-48a2-8349-c075e56a0440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_ids.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_",
        "colab_type": "text"
      },
      "source": [
        "## 3.4. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06",
        "colab_type": "text"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab_type": "code",
        "outputId": "448b5a36-10a7-483d-c3ff-b15aa6999236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45,000 training samples\n",
            "5,000 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN",
        "colab_type": "text"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-",
        "colab_type": "text"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX",
        "colab_type": "text"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc",
        "colab_type": "text"
      },
      "source": [
        "## 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab_type": "code",
        "outputId": "40d734b9-9c4f-42c4-b72d-bfe9e15390ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b88687353f4849fb8416f8f5ce312ddf",
            "a8e8492862fd451093195601ac1ccfbf",
            "3d8d43783e074dd28da6dbaee8421585",
            "5893c7dbce8743b8b1d155120c5015ee",
            "0a4a783abe874a3987d3537d0303a640",
            "42e39ada1cc244a69f6cfa83bc4f05f1",
            "63fa6c96176f463da858e0bc685d0f3e",
            "91679ab3502942e5b91fe9aff10c8d03",
            "6dcca7586f1641eb830335e1acaa6336",
            "730ad497fbcd4f27a07514283e4ae29e",
            "a70084abd73040bdb989431d2543ae5d",
            "a9bb268b635d4ebb95be00729b0c7e76",
            "6ac0d181ba694221a5eb94145c140ac1",
            "4b17b2dd2b3b4381a216f7964e0fc0e4",
            "0eb011ad90c1427ea649500112dd0972",
            "d11f1362f34b4dfd91e4d559b3a14367"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b88687353f4849fb8416f8f5ce312ddf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dcca7586f1641eb830335e1acaa6336",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx",
        "colab_type": "text"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4 (we'll see that this is probably too many...)\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox",
        "colab_type": "text"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5",
        "colab_type": "text"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
        "\n",
        "\n",
        "**Training:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. \n",
        "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Evalution:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress\n",
        "\n",
        "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
        "\n",
        "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3",
        "colab_type": "text"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N",
        "colab_type": "text"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab_type": "code",
        "outputId": "ca545805-a350-4470-9d4d-909dfb01b7c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:09.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:00:26.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:00:43.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:00:51.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:01:00.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:01:08.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:01:17.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:01:25.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:01:34.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:01:42.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:01:51.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:01:59.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:02:08.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:02:16.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:02:25.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:02:33.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:02:41.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:02:50.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:02:58.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:03:07.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:03:15.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:03:24.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:03:32.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:03:41.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:03:49.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:03:58.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:04:06.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:04:15.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:04:23.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:04:32.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:04:40.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:04:49.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:04:57.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:04:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:00:51.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:01:08.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:01:25.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:01:33.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:01:42.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:01:50.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:01:59.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:02:07.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:02:16.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:02:24.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:02:33.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:02:41.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:02:50.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:02:58.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:03:06.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:03:15.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:03:23.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:03:32.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:03:40.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:03:49.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:03:57.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:04:06.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:04:14.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:04:23.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:04:31.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:04:40.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:04:48.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:04:57.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:04:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.35\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:00:51.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:01:08.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:01:25.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:01:33.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:01:42.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:01:50.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:01:59.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:02:07.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:02:16.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:02:24.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:02:33.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:02:41.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:02:49.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:02:58.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:03:06.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:03:15.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:03:23.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:03:32.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:03:40.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:03:49.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:03:57.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:04:06.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:04:14.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:04:23.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:04:31.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:04:40.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:04:48.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:04:57.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:04:58\n",
            "\n",
            "Running Validation...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4",
        "colab_type": "text"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab_type": "code",
        "outputId": "164ea346-a5db-45c5-b0af-f738aee1fec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:04:58</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:04:58</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:04:57</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.09</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:04:57</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.40         0.35           0.84       0:04:58         0:00:09\n",
              "2               0.26         0.37           0.85       0:04:58         0:00:09\n",
              "3               0.15         0.48           0.85       0:04:57         0:00:09\n",
              "4               0.09         0.61           0.85       0:04:57         0:00:09"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI",
        "colab_type": "text"
      },
      "source": [
        "Notice that, while the the training loss is going down with each epoch, the validation loss is increasing! This suggests that we are training our model too long, and it's over-fitting on the training data. \n",
        "\n",
        "(For reference, we are using 7,695 training samples and 856 validation samples).\n",
        "\n",
        "Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on. \n",
        "\n",
        "If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab_type": "code",
        "outputId": "a43ac514-6e1b-4def-e2d6-225a18c83431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pip1C_p1QJ54",
        "colab_type": "text"
      },
      "source": [
        "# Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8",
        "colab_type": "text"
      },
      "source": [
        "## A1. Saving & Loading Fine-Tuned Model\n",
        "\n",
        "This first cell (taken from `run_glue.py` [here](https://github.com/huggingface/transformers/blob/35ff345fc9df9e777b27903f11fa213e4052595b/examples/run_glue.py#L495)) writes the model and tokenizer out to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab_type": "code",
        "outputId": "a5517081-2e05-4244-c8df-77a9558ff75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-tjHkR7lc1I",
        "colab_type": "text"
      },
      "source": [
        "Let's check out the file sizes, out of curiosity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab_type": "code",
        "outputId": "6df0b283-6458-4d95-8455-2e7537193d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427960K\n",
            "-rw-r--r-- 1 root root      2K Mar 18 15:53 config.json\n",
            "-rw-r--r-- 1 root root 427719K Mar 18 15:53 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Mar 18 15:53 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Mar 18 15:53 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Mar 18 15:53 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr_bt2rFlgDn",
        "colab_type": "text"
      },
      "source": [
        "The largest file is the model weights, at around 418 megabytes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab_type": "code",
        "outputId": "70780762-7790-474f-e5c2-304a066945ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 418M Mar 18 15:53 ./model_save/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzGKvOFAll_e",
        "colab_type": "text"
      },
      "source": [
        "To save your model across Colab Notebook sessions, download it to your local machine, or ideally copy it to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trr-A-POC18_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ \"./gdrive/My Drive/Colab Notebooks/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vstijw85SZ",
        "colab_type": "text"
      },
      "source": [
        "The following functions will load the model back from disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nskPzUM084zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = model_class.from_pretrained(output_dir)\n",
        "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}