{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Classification Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3dec3bc44bf744c989abcf76b0adaf07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c39d298373f340d287575b8d4d0cd3bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_260fa87e975d4f868968b60510f1a667",
              "IPY_MODEL_c3a1cd6cffab494eaa7b9662e43f6392"
            ]
          }
        },
        "c39d298373f340d287575b8d4d0cd3bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "260fa87e975d4f868968b60510f1a667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01d9457651264b5dae2568edf9366d5f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d65534278894a56bb4edc7ce14ca3c9"
          }
        },
        "c3a1cd6cffab494eaa7b9662e43f6392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6fa4177eec0466784cea1c6d5c9380d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 813kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ab06dc7ff39452fbb85255147b59440"
          }
        },
        "01d9457651264b5dae2568edf9366d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d65534278894a56bb4edc7ce14ca3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6fa4177eec0466784cea1c6d5c9380d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ab06dc7ff39452fbb85255147b59440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b88687353f4849fb8416f8f5ce312ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8e8492862fd451093195601ac1ccfbf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d8d43783e074dd28da6dbaee8421585",
              "IPY_MODEL_5893c7dbce8743b8b1d155120c5015ee"
            ]
          }
        },
        "a8e8492862fd451093195601ac1ccfbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d8d43783e074dd28da6dbaee8421585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a4a783abe874a3987d3537d0303a640",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42e39ada1cc244a69f6cfa83bc4f05f1"
          }
        },
        "5893c7dbce8743b8b1d155120c5015ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63fa6c96176f463da858e0bc685d0f3e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 361/361 [00:11&lt;00:00, 31.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91679ab3502942e5b91fe9aff10c8d03"
          }
        },
        "0a4a783abe874a3987d3537d0303a640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42e39ada1cc244a69f6cfa83bc4f05f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63fa6c96176f463da858e0bc685d0f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91679ab3502942e5b91fe9aff10c8d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dcca7586f1641eb830335e1acaa6336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_730ad497fbcd4f27a07514283e4ae29e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a70084abd73040bdb989431d2543ae5d",
              "IPY_MODEL_a9bb268b635d4ebb95be00729b0c7e76"
            ]
          }
        },
        "730ad497fbcd4f27a07514283e4ae29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a70084abd73040bdb989431d2543ae5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ac0d181ba694221a5eb94145c140ac1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b17b2dd2b3b4381a216f7964e0fc0e4"
          }
        },
        "a9bb268b635d4ebb95be00729b0c7e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0eb011ad90c1427ea649500112dd0972",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 42.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d11f1362f34b4dfd91e4d559b3a14367"
          }
        },
        "6ac0d181ba694221a5eb94145c140ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b17b2dd2b3b4381a216f7964e0fc0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0eb011ad90c1427ea649500112dd0972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d11f1362f34b4dfd91e4d559b3a14367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvanommeren/nlp-benchmark/blob/master/BERT_Classification_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej",
        "colab_type": "text"
      },
      "source": [
        "# BERT Classification IMDB PyTorch\n",
        "\n",
        "Based on the `BERT Fine-Tuning Tutorial with PyTorch` of Chris McCormick and Nick Ryan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab_type": "code",
        "outputId": "f517dae1-d410-4ab4-ba06-19239366614c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab_type": "code",
        "outputId": "35c49a15-c215-4c4d-ae3c-ecd0cbb6262c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab_type": "code",
        "outputId": "b6ff46d4-baf7-4c3a-aebe-503c8c1d0ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 29.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 4.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 15.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 26.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=5e7b303823d4591113f62912773241a0cce9ef151d9eac9625074f6da02a7c4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihMAlloSeNma",
        "colab_type": "code",
        "outputId": "17cd1410-66d0-4a56-ec15-6b1bfb90c429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGdCHoYbes00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file = 'gdrive/My Drive/Colab Notebooks/IMDB Dataset.csv'\n",
        "\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "SAMPLE_SIZE = 50000\n",
        "\n",
        "def preprocess_imdb_raw_data(x):\n",
        "    x = re.sub(\"<br\\\\s*/?>\", \" \", x)\n",
        "    return x \n",
        "\n",
        "X = [preprocess_imdb_raw_data(x) for x in df['review'].values][:SAMPLE_SIZE]\n",
        "\n",
        "y = df['sentiment'].apply(lambda x: int(x == 'positive')).values[:SAMPLE_SIZE]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = X\n",
        "labels = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct",
        "colab_type": "text"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab_type": "code",
        "outputId": "2832bb9c-b3a3-4d87-f97b-5628757456df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "3dec3bc44bf744c989abcf76b0adaf07",
            "c39d298373f340d287575b8d4d0cd3bc",
            "260fa87e975d4f868968b60510f1a667",
            "c3a1cd6cffab494eaa7b9662e43f6392",
            "01d9457651264b5dae2568edf9366d5f",
            "5d65534278894a56bb4edc7ce14ca3c9",
            "a6fa4177eec0466784cea1c6d5c9380d",
            "7ab06dc7ff39452fbb85255147b59440"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dec3bc44bf744c989abcf76b0adaf07",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIWAoWL2RK1p",
        "colab_type": "text"
      },
      "source": [
        "Now we're ready to perform the real tokenization.\n",
        "\n",
        "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
        "\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "4. Pad or truncate all sentences to the same length.\n",
        "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
        "\n",
        "The first four features are in `tokenizer.encode`, but I'm using `tokenizer.encode_plus` to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0SIJSHbdM-",
        "colab_type": "code",
        "outputId": "ed565af9-6f17-48a2-8349-c075e56a0440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_ids.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_",
        "colab_type": "text"
      },
      "source": [
        "## 3.4. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06",
        "colab_type": "text"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab_type": "code",
        "outputId": "448b5a36-10a7-483d-c3ff-b15aa6999236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45,000 training samples\n",
            "5,000 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN",
        "colab_type": "text"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-",
        "colab_type": "text"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX",
        "colab_type": "text"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc",
        "colab_type": "text"
      },
      "source": [
        "## 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab_type": "code",
        "outputId": "40d734b9-9c4f-42c4-b72d-bfe9e15390ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b88687353f4849fb8416f8f5ce312ddf",
            "a8e8492862fd451093195601ac1ccfbf",
            "3d8d43783e074dd28da6dbaee8421585",
            "5893c7dbce8743b8b1d155120c5015ee",
            "0a4a783abe874a3987d3537d0303a640",
            "42e39ada1cc244a69f6cfa83bc4f05f1",
            "63fa6c96176f463da858e0bc685d0f3e",
            "91679ab3502942e5b91fe9aff10c8d03",
            "6dcca7586f1641eb830335e1acaa6336",
            "730ad497fbcd4f27a07514283e4ae29e",
            "a70084abd73040bdb989431d2543ae5d",
            "a9bb268b635d4ebb95be00729b0c7e76",
            "6ac0d181ba694221a5eb94145c140ac1",
            "4b17b2dd2b3b4381a216f7964e0fc0e4",
            "0eb011ad90c1427ea649500112dd0972",
            "d11f1362f34b4dfd91e4d559b3a14367"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b88687353f4849fb8416f8f5ce312ddf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dcca7586f1641eb830335e1acaa6336",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx",
        "colab_type": "text"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4 (we'll see that this is probably too many...)\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox",
        "colab_type": "text"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5",
        "colab_type": "text"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
        "\n",
        "\n",
        "**Training:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. \n",
        "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Evalution:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress\n",
        "\n",
        "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
        "\n",
        "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3",
        "colab_type": "text"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N",
        "colab_type": "text"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab_type": "code",
        "outputId": "ca545805-a350-4470-9d4d-909dfb01b7c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:09.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:00:26.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:00:43.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:00:51.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:01:00.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:01:08.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:01:17.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:01:25.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:01:34.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:01:42.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:01:51.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:01:59.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:02:08.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:02:16.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:02:25.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:02:33.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:02:41.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:02:50.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:02:58.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:03:07.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:03:15.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:03:24.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:03:32.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:03:41.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:03:49.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:03:58.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:04:06.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:04:15.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:04:23.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:04:32.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:04:40.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:04:49.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:04:57.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:04:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:00:51.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:01:08.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:01:25.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:01:33.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:01:42.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:01:50.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:01:59.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:02:07.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:02:16.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:02:24.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:02:33.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:02:41.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:02:50.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:02:58.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:03:06.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:03:15.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:03:23.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:03:32.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:03:40.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:03:49.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:03:57.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:04:06.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:04:14.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:04:23.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:04:31.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:04:40.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:04:48.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:04:57.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:04:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.35\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:00:51.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:01:08.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:01:25.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:01:33.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:01:42.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:01:50.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:01:59.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:02:07.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:02:16.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:02:24.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:02:33.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:02:41.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:02:49.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:02:58.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:03:06.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:03:15.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:03:23.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:03:32.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:03:40.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:03:49.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:03:57.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:04:06.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:04:14.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:04:23.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:04:31.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:04:40.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:04:48.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:04:57.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:04:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.42\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:08.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:00:17.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:00:25.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:00:34.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:00:42.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:00:51.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:00:59.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:01:08.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:01:16.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:01:25.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:01:33.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:01:42.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:01:50.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:01:59.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:02:07.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:02:15.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:02:24.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:02:32.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:02:41.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:02:49.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:02:58.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:03:06.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:03:15.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:03:23.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:03:32.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:03:40.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:03:49.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:03:57.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:04:05.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:04:14.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:04:22.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:04:31.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:04:39.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:04:48.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:04:56.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:04:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:20:29 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4",
        "colab_type": "text"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab_type": "code",
        "outputId": "bb6b2a26-7a19-4cb1-a8d6-18e555b50340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:04:58</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:04:58</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:04:58</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.09</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:04:58</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.39         0.33           0.86       0:04:58         0:00:09\n",
              "2               0.25         0.35           0.86       0:04:58         0:00:09\n",
              "3               0.15         0.42           0.86       0:04:58         0:00:09\n",
              "4               0.09         0.58           0.86       0:04:58         0:00:09"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI",
        "colab_type": "text"
      },
      "source": [
        "Notice that, while the the training loss is going down with each epoch, the validation loss is increasing! This suggests that we are training our model too long, and it's over-fitting on the training data. \n",
        "\n",
        "(For reference, we are using 7,695 training samples and 856 validation samples).\n",
        "\n",
        "Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on. \n",
        "\n",
        "If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab_type": "code",
        "outputId": "515a1861-e05b-45f7-8e30-44284cd77d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pip1C_p1QJ54",
        "colab_type": "text"
      },
      "source": [
        "# Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8",
        "colab_type": "text"
      },
      "source": [
        "## A1. Saving & Loading Fine-Tuned Model\n",
        "\n",
        "This first cell (taken from `run_glue.py` [here](https://github.com/huggingface/transformers/blob/35ff345fc9df9e777b27903f11fa213e4052595b/examples/run_glue.py#L495)) writes the model and tokenizer out to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab_type": "code",
        "outputId": "a5517081-2e05-4244-c8df-77a9558ff75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-tjHkR7lc1I",
        "colab_type": "text"
      },
      "source": [
        "Let's check out the file sizes, out of curiosity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab_type": "code",
        "outputId": "6df0b283-6458-4d95-8455-2e7537193d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427960K\n",
            "-rw-r--r-- 1 root root      2K Mar 18 15:53 config.json\n",
            "-rw-r--r-- 1 root root 427719K Mar 18 15:53 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Mar 18 15:53 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Mar 18 15:53 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Mar 18 15:53 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr_bt2rFlgDn",
        "colab_type": "text"
      },
      "source": [
        "The largest file is the model weights, at around 418 megabytes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab_type": "code",
        "outputId": "70780762-7790-474f-e5c2-304a066945ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 418M Mar 18 15:53 ./model_save/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzGKvOFAll_e",
        "colab_type": "text"
      },
      "source": [
        "To save your model across Colab Notebook sessions, download it to your local machine, or ideally copy it to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trr-A-POC18_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ \"./gdrive/My Drive/Colab Notebooks/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vstijw85SZ",
        "colab_type": "text"
      },
      "source": [
        "The following functions will load the model back from disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nskPzUM084zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = model_class.from_pretrained(output_dir)\n",
        "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}